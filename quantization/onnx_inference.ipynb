{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
    "\n",
    "def load_model(onnx_file_path):\n",
    "    session = ort.InferenceSession(onnx_file_path, providers=['CPUExecutionProvider'])\n",
    "    return session\n",
    "\n",
    "def run_model(session, input_data):\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_names = [output.name for output in session.get_outputs()]\n",
    "    print(\"22\", len(output_names))\n",
    "    print(input_name)\n",
    "    results = session.run(output_names, {input_name: input_data})\n",
    "    return results\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     onnx_file_path = \"./assets/resnet50_csv_26_inf_900x1200.onnx\"\n",
    "#     session = load_model(onnx_file_path)\n",
    "#     image_path = './images/validation_image_cmu/10.6.3.9 Flat margin.jpg'\n",
    "#     target_size = (1200, 900)\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = image.resize(target_size)\n",
    "#     image_array = np.asarray(image)\n",
    "#     image_array = image_array.astype(np.float32) / 255.0\n",
    "#     image_array = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "#     # print(\"Model Input:\", image_array)\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     results = run_model(session, image_array)\n",
    "#     end_time = time.time()\n",
    "    \n",
    "#     print('Inference session.get_outputs():',results)\n",
    "#     print('Inference Time:', end_time - start_time, 'seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Works for Quantized Int8 and Unquantized model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess_image(x, mode='caffe'):\n",
    "    \n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "    if mode == 'tf':\n",
    "        x /= 127.5\n",
    "        x -= 1.\n",
    "    elif mode == 'caffe':\n",
    "        x -= [103.939, 116.779, 123.68]\n",
    "\n",
    "    return x\n",
    "\n",
    "def resize_image(img, min_side=900, max_side=1200):\n",
    "\n",
    "    scale = compute_resize_scale(img.shape, min_side=min_side, max_side=max_side)\n",
    "\n",
    "    # resize the image with the computed scale\n",
    "    img = cv2.resize(img, None, fx=scale, fy=scale)\n",
    "\n",
    "    return img, scale\n",
    "\n",
    "def compute_resize_scale(image_shape, min_side=900, max_side=1200):\n",
    "    \n",
    "    (rows, cols, _) = image_shape\n",
    "\n",
    "    smallest_side = min(rows, cols)\n",
    "\n",
    "    # rescale the image so the smallest side is min_side\n",
    "    scale = min_side / smallest_side\n",
    "\n",
    "    # check if the largest side is now greater than max_side, which can happen\n",
    "    # when images have a large aspect ratio\n",
    "    largest_side = max(rows, cols)\n",
    "    if largest_side * scale > max_side:\n",
    "        scale = max_side / largest_side\n",
    "\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 1200, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_ = './images/validation_image_cmu/10.6.3.9 Flat margin.jpg'\n",
    "\n",
    "image = Image.open(image_path_).convert('RGB')\n",
    "\n",
    "image = image.rotate(90)\n",
    "image = np.asarray(image)\n",
    "image = image[:, :, ::-1].copy()\n",
    "image = preprocess_image(image)\n",
    "image__, scale = resize_image(image)\n",
    "image__.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_(session, input_data):\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_names = [output.name for output in session.get_outputs()]\n",
    "    print(\"22\", len(output_names))\n",
    "    print(input_name)\n",
    "    results = session.run(output_names, {input_name: input_data})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unquantized Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file_path = \"./assets/resnet50_csv_26_inf_900x1200.onnx\"\n",
    "session_1 = ort.InferenceSession(onnx_file_path, providers=['CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 3\n",
      "input_1:0\n",
      "Inference session.get_outputs(): [array([[[ 1.8300137e+02,  1.6337952e+01,  1.0949430e+03,  9.0000000e+02],\n",
      "        [ 2.1348184e+02,  0.0000000e+00,  1.1051562e+03,  9.0000000e+02],\n",
      "        [-1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00],\n",
      "        ...,\n",
      "        [-1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00],\n",
      "        [-1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00],\n",
      "        [-1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00]]],\n",
      "      dtype=float32), array([[ 0.54041857,  0.24755007, -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ]],\n",
      "      dtype=float32), array([[ 1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]], dtype=int32)]\n",
      "Inference Time: 5.982309818267822 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "results = run_model_(session_1, np.expand_dims(image__, axis=0))\n",
    "end_time = time.time()\n",
    "\n",
    "print('Inference session.get_outputs():',results)\n",
    "print('Inference Time:', end_time - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantized Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file_path_quant = \"./assets/resnet50_csv_26_inf_900x1200_Quantized.onnx\"\n",
    "session_quant = ort.InferenceSession(onnx_file_path_quant, providers=['CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 3\n",
      "input_1:0\n",
      "Inference session.get_outputs(): [array([[[ 1.8355899e+02,  1.7561951e+01,  1.0942911e+03,  9.0000000e+02],\n",
      "        [ 2.1642825e+02,  0.0000000e+00,  1.1028279e+03,  9.0000000e+02],\n",
      "        [-1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00],\n",
      "        ...,\n",
      "        [-1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00],\n",
      "        [-1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00],\n",
      "        [-1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00]]],\n",
      "      dtype=float32), array([[ 0.5345413 ,  0.24685106, -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ]],\n",
      "      dtype=float32), array([[ 1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]], dtype=int32)]\n",
      "Inference Time: 8.089977025985718 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "results = run_model_(session_quant, np.expand_dims(image__, axis=0))\n",
    "end_time = time.time()\n",
    "\n",
    "print('Inference session.get_outputs():',results)\n",
    "print('Inference Time:', end_time - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FP16 Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:37:50.719250 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add'\n",
      "2023-11-24 12:37:50.719479 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add_1'\n",
      "2023-11-24 12:37:50.719776 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add'\n",
      "2023-11-24 12:37:50.719955 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add_1'\n",
      "2023-11-24 12:37:50.720264 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add'\n",
      "2023-11-24 12:37:50.720395 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add_1'\n",
      "2023-11-24 12:37:50.720731 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add'\n",
      "2023-11-24 12:37:50.720852 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add_1'\n",
      "2023-11-24 12:37:50.721151 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add'\n",
      "2023-11-24 12:37:50.721279 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add_1'\n",
      "2023-11-24 12:37:50.722461 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Less node 'copy__76/filtered_detections/map/while/Less_1'\n",
      "2023-11-24 12:37:50.732165 [W:onnxruntime:, graph.cc:3553 CleanUnusedInitializersAndNodeArgs] Removing initializer 'const_fold_opt__1035'. It is not used by any node and should be removed from the model.\n",
      "2023-11-24 12:37:50.732177 [W:onnxruntime:, graph.cc:3553 CleanUnusedInitializersAndNodeArgs] Removing initializer 'const_fold_opt__1037'. It is not used by any node and should be removed from the model.\n",
      "2023-11-24 12:37:50.745402 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add'\n",
      "2023-11-24 12:37:50.745464 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add_1'\n",
      "2023-11-24 12:37:50.745501 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add'\n",
      "2023-11-24 12:37:50.745532 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add_1'\n",
      "2023-11-24 12:37:50.745564 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add'\n",
      "2023-11-24 12:37:50.745594 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add_1'\n",
      "2023-11-24 12:37:50.745682 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add'\n",
      "2023-11-24 12:37:50.745720 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add_1'\n",
      "2023-11-24 12:37:50.745753 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add'\n",
      "2023-11-24 12:37:50.745786 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add_1'\n",
      "2023-11-24 12:37:50.745871 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Less node 'copy__76/filtered_detections/map/while/Less_1'\n",
      "2023-11-24 12:37:50.756724 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add'\n",
      "2023-11-24 12:37:50.756774 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add_1'\n",
      "2023-11-24 12:37:50.756821 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add'\n",
      "2023-11-24 12:37:50.756862 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add_1'\n",
      "2023-11-24 12:37:50.756915 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add'\n",
      "2023-11-24 12:37:50.756962 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add_1'\n",
      "2023-11-24 12:37:50.757001 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add'\n",
      "2023-11-24 12:37:50.757050 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add_1'\n",
      "2023-11-24 12:37:50.757086 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add'\n",
      "2023-11-24 12:37:50.757119 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add_1'\n",
      "2023-11-24 12:37:50.757184 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Less node 'copy__76/filtered_detections/map/while/Less_1'\n",
      "2023-11-24 12:37:50.768102 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add'\n",
      "2023-11-24 12:37:50.768147 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add_1'\n",
      "2023-11-24 12:37:50.768186 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add'\n",
      "2023-11-24 12:37:50.768273 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add_1'\n",
      "2023-11-24 12:37:50.768333 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add'\n",
      "2023-11-24 12:37:50.768399 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add_1'\n",
      "2023-11-24 12:37:50.768505 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add'\n",
      "2023-11-24 12:37:50.768544 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add_1'\n",
      "2023-11-24 12:37:50.768599 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add'\n",
      "2023-11-24 12:37:50.768632 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add_1'\n",
      "2023-11-24 12:37:50.768701 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Less node 'copy__76/filtered_detections/map/while/Less_1'\n",
      "2023-11-24 12:37:50.786927 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add'\n",
      "2023-11-24 12:37:50.786984 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add_1'\n",
      "2023-11-24 12:37:50.787022 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add'\n",
      "2023-11-24 12:37:50.787057 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add_1'\n",
      "2023-11-24 12:37:50.787105 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add'\n",
      "2023-11-24 12:37:50.787139 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add_1'\n",
      "2023-11-24 12:37:50.787173 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add'\n",
      "2023-11-24 12:37:50.787205 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add_1'\n",
      "2023-11-24 12:37:50.787237 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anc"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hors_3/add'\n",
      "2023-11-24 12:37:50.787318 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add_1'\n",
      "2023-11-24 12:37:50.787378 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Less node 'copy__76/filtered_detections/map/while/Less_1'\n",
      "2023-11-24 12:37:50.814232 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add'\n",
      "2023-11-24 12:37:50.814377 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add_1'\n",
      "2023-11-24 12:37:50.814599 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add'\n",
      "2023-11-24 12:37:50.814668 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add_1'\n",
      "2023-11-24 12:37:50.814726 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add'\n",
      "2023-11-24 12:37:50.814759 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add_1'\n",
      "2023-11-24 12:37:50.814813 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add'\n",
      "2023-11-24 12:37:50.814943 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add_1'\n",
      "2023-11-24 12:37:50.815181 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add'\n",
      "2023-11-24 12:37:50.815213 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add_1'\n",
      "2023-11-24 12:37:50.815292 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Less node 'copy__76/filtered_detections/map/while/Less_1'\n",
      "2023-11-24 12:37:50.833011 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add'\n",
      "2023-11-24 12:37:50.833054 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add_1'\n",
      "2023-11-24 12:37:50.833088 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add'\n",
      "2023-11-24 12:37:50.833119 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add_1'\n",
      "2023-11-24 12:37:50.833189 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add'\n",
      "2023-11-24 12:37:50.833266 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add_1'\n",
      "2023-11-24 12:37:50.833337 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add'\n",
      "2023-11-24 12:37:50.833391 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add_1'\n",
      "2023-11-24 12:37:50.833567 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add'\n",
      "2023-11-24 12:37:50.833604 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add_1'\n",
      "2023-11-24 12:37:50.833681 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Less node 'copy__76/filtered_detections/map/while/Less_1'\n",
      "2023-11-24 12:37:50.849258 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add'\n",
      "2023-11-24 12:37:50.849370 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add_1'\n",
      "2023-11-24 12:37:50.849425 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add'\n",
      "2023-11-24 12:37:50.849494 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add_1'\n",
      "2023-11-24 12:37:50.849598 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add'\n",
      "2023-11-24 12:37:50.849681 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add_1'\n",
      "2023-11-24 12:37:50.849735 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add'\n",
      "2023-11-24 12:37:50.849787 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add_1'\n",
      "2023-11-24 12:37:50.849824 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add'\n",
      "2023-11-24 12:37:50.849951 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add_1'\n",
      "2023-11-24 12:37:50.850049 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Less node 'copy__76/filtered_detections/map/while/Less_1'\n",
      "2023-11-24 12:37:50.867866 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add'\n",
      "2023-11-24 12:37:50.868011 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add_1'\n",
      "2023-11-24 12:37:50.868052 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add'\n",
      "2023-11-24 12:37:50.868086 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add_1'\n",
      "2023-11-24 12:37:50.868121 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add'\n",
      "2023-11-24 12:37:50.868153 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add_1'\n",
      "2023-11-24 12:37:50.868189 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add'\n",
      "2023-11-24 12:37:50.868223 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add_1'\n",
      "2023-11-24 12:37:50.868258 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add'\n",
      "2023-11-24 12:37:50.868292 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add_1'\n",
      "2023-11-24 12:37:50.868353 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Less node 'copy__76/filtered_detections/map/while/Less_1'\n",
      "2023-11-24 12:37:50.886609 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add'\n",
      "2023-11-24 12:37:50.886674 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_0/add_1'\n",
      "2023-11-24 12:37:50.886711 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add'\n",
      "2023-11-24 12:37:50.886743 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_1/add_1'\n",
      "2023-11-24 12:37:50.886895 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add'\n",
      "2023-11-24 12:37:50.886954 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_2/add_1'\n",
      "2023-11-24 12:37:50.887036 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add'\n",
      "2023-11-24 12:37:50.887103 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_4/add_1'\n",
      "2023-11-24 12:37:50.887151 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add'\n",
      "2023-11-24 12:37:50.887194 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Add node 'anchors_3/add_1'\n",
      "2023-11-24 12:37:50.887307 [W:onnxruntime:, constant_folding.cc:212 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Less node 'copy__76/filtered_detections/map/while/Less_1'\n"
     ]
    }
   ],
   "source": [
    "onnx_file_path_fp16 = \"./assets/resnet50_csv_26_inf_900x1200_FP16.onnx\"\n",
    "session_fp16 = ort.InferenceSession(onnx_file_path_fp16, providers=['CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 3\n",
      "input_1:0\n",
      "Inference session.get_outputs(): [array([[[ 1.830e+02,  1.672e+01,  1.094e+03,  9.000e+02],\n",
      "        [ 2.141e+02,  0.000e+00,  1.105e+03,  9.000e+02],\n",
      "        [-1.000e+00, -1.000e+00, -1.000e+00, -1.000e+00],\n",
      "        ...,\n",
      "        [-1.000e+00, -1.000e+00, -1.000e+00, -1.000e+00],\n",
      "        [-1.000e+00, -1.000e+00, -1.000e+00, -1.000e+00],\n",
      "        [-1.000e+00, -1.000e+00, -1.000e+00, -1.000e+00]]], dtype=float16), array([[ 0.541 ,  0.2477, -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ,\n",
      "        -1.    , -1.    , -1.    , -1.    , -1.    , -1.    ]],\n",
      "      dtype=float16), array([[ 1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]], dtype=int32)]\n",
      "Inference Time: 5.951932191848755 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "results = run_model_(session_fp16, np.expand_dims(image__.astype(np.float16), axis=0))\n",
    "end_time = time.time()\n",
    "\n",
    "print('Inference session.get_outputs():',results)\n",
    "print('Inference Time:', end_time - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_pc_cpu(model_path, image_paths):\n",
    "    \n",
    "    labels_to_names = {0: 'non_cancer', 1: 'cancer'}\n",
    "    model = load_model(model_path, backbone_name='resnet50')\n",
    "    try:\n",
    "        model = models.convert_model(model)\n",
    "    except:\n",
    "        print(\"Model is likely already an inference model\")\n",
    "    results = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Load and preprocess the image\n",
    "        # print(\"Loading Image: {}\".format(image_path))\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        image = image.rotate(90)\n",
    "            \n",
    "        image = np.asarray(image)\n",
    "        image = image[:, :, ::-1].copy()\n",
    "        image = preprocess_image(image)\n",
    "        image, scale = resize_image(image)\n",
    "\n",
    "        # Run the inference\n",
    "        start = time.time()\n",
    "        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "        inference_time = time.time() - start\n",
    "        predicted_label = labels[0][np.argmax(scores[0])]\n",
    "        confidence = scores[0][np.argmax(scores[0])]\n",
    "        \n",
    "        results.append({'isCancerDetected': predicted_label, 'InferenceTime': inference_time, 'Confidence2': confidence})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantization to INT8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = './assets/resnet50_csv_26_inf_900x1200.onnx'\n",
    "model_quant = './assets/resnet50_csv_26_inf_900x1200_Quantized.onnx'\n",
    "\n",
    "quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantization to FP16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 2.753519900977608e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.7733264573726046e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 2.926357378640887e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.5995977875604694e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 7.365299126149694e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.1630011620411551e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.1306173774983108e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.8644971788717157e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -8.593152500679935e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 2.4490981687108615e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.207384319774519e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 2.72620575003657e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 4.444479273502111e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -5.1806498646556065e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 2.990006109371279e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -6.44956941187047e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.8279972141831422e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -5.8439731276394014e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -5.6807518689083736e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -3.629632772117475e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 3.857917985072845e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -6.910326533215994e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 3.032138096159542e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -9.367064457421748e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.7098660265446597e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -5.3209191719361115e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 9.225681196767255e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.79819836588058e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -3.647041335597123e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 4.689692190140704e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.685786064191234e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.606749222560211e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.1686810387252535e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.389993625229181e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -8.284342989384186e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.3614557481389511e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -8.271573648244157e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.918292052456195e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 8.207600821208416e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -4.196889058505349e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -7.647155797485539e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.344962517028762e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -5.492031007747755e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.47116532289715e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 2.5069994080695324e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -5.2136268635649685e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 6.51753850888781e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -4.761614036397077e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 9.922928256855812e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.4811121218372136e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 8.617007551947609e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.2388348952517845e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:50: UserWarning: the float32 number -inf will be truncated to -10000.0\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_min, -max_finite_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -4.390955155031406e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.0535062600069978e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.5516300183880958e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.143704839838392e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.2432072199762843e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 7.3689694346512624e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.3682580402019084e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -8.06721516255493e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 3.3136359434138285e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.2505161350873095e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 2.950723931860466e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.3838782564334906e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -3.2791720450120465e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.957622730586195e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.9469426959517477e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 4.9997971984794276e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.952933148530178e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -3.0973360765074176e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/Users/bekiretta/miniforge3/envs/capstone/lib/python3.8/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -3.4215497102252357e-09 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnxconverter_common import float16\n",
    "\n",
    "model = onnx.load(\"./assets/resnet50_csv_26_inf_900x1200.onnx\")\n",
    "model_fp16 = float16.convert_float_to_float16(model)\n",
    "onnx.save(model_fp16, \"./assets/resnet50_csv_26_inf_900x1200_FP16.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 9.5367431640625e-07 seconds\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "def load_model(onnx_file_path):\n",
    "    session = ort.InferenceSession(onnx_file_path, providers=['CPUExecutionProvider'])\n",
    "    return session\n",
    "\n",
    "def run_model(session, input_data):\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_names = [output.name for output in session.get_outputs()]\n",
    "    print(\"22\", len(output_names))\n",
    "    print(input_name)\n",
    "    results = session.run(output_names, {input_name: input_data})\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # onnx_file_path = \"./assets/resnet50_csv_26_inf_900x1200_Quantized.onnx\"\n",
    "    # session = load_model(onnx_file_path)\n",
    "    # image_path = './images/validation_image_cmu/10.6.3.9 Flat margin.jpg'\n",
    "    # target_size = (1200, 900)\n",
    "    # image = Image.open(image_path).convert('RGB')\n",
    "    # image = image.resize(target_size)\n",
    "    # image_array = np.asarray(image)\n",
    "    # image_array = image_array.astype(np.float32) / 255.0\n",
    "    # image_array = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    # # print(\"Model Input:\", image_array)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # results = run_model(session, image_array)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # print('Inference session.get_outputs():',results)\n",
    "    print('Inference Time:', end_time - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
